{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94fd6d5e-bb35-4798-8044-028b9352771c",
   "metadata": {},
   "source": [
    "# 矩阵计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14348e5b-5d7c-48b9-b04a-08f46cbe3cdf",
   "metadata": {},
   "source": [
    "**假设对函数  y = 2xTx 关于列向量x求导**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fa55c82-143b-42a0-a54f-0cf596459fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e02cfe-da46-48b1-95fa-204737cd2523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.0)\n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41597fdc-9e58-4f9c-9441-1c6d45ed1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.requires_grad_(True)  # 申明需要求梯度后梯度保存的值空间  等价于 x = torch.arange(4.0, requires_grad=True)\n",
    "x.grad  #后续可通过 x.grad 获取梯度，初始值是None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f87aeb4-f464-40f7-89b2-dbec246d50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2 * torch.dot(x,x)  # y关于x的函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef9e526a-74a0-4107-aadf-d8d476f68af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()    #调用反向传播计算y关于x每一个分量的梯度\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ea160af-8379-4b87-994d-2a20c43463d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y = 2xTx  的梯度应该为 2*2x = 4x\n",
    "x.grad == 4*x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96331a3-e869-42cc-9db1-f303151c953b",
   "metadata": {},
   "source": [
    "**在默认情况下，pytorch会积累梯度，我们需要清除之前的值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e836acb4-882e-4660-8e5c-358f63659f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x.sum()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a708f-dd7c-4af1-894a-fb2857db0e7f",
   "metadata": {},
   "source": [
    "**深度学习中，我们的目的不是计算微分矩阵，而是批量中每个样本单独计算的偏导数之和**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057d8cd-4cd2-49dc-969c-eaa638c1e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对非标量调用‘backward'需要传入一个'gradient'参数，该参数指定微分函数关于self的梯度\n",
    "x.grad.zero_()\n",
    "y = x * x "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
